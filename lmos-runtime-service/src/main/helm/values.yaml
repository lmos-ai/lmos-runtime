# Default values for lmos-runtime.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/lmos-ai/lmos-runtime
  pullPolicy: IfNotPresent

nameOverride: "lmos-runtime"
fullnameOverride: "lmos-runtime"

serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext: {}
#  fsGroup: 1000
#  runAsGroup: 1000
#  runAsNonRoot: true
#  runAsUser: 1002
#  seccompProfile:
#    type: RuntimeDefault
#  supplementalGroups:
#    - 1000

securityContext: {}
#  allowPrivilegeEscalation: false
#  readOnlyRootFilesystem: true
#  capabilities:
#    drop:
#    - ALL

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: false
  className: ""
  annotations: {}
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []

resources: {}

livenessProbe:
  initialDelaySeconds: 1
  periodSeconds: 15
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 6

readinessProbe:
  initialDelaySeconds: 1
  periodSeconds: 15
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 3

startupProbe:
  initialDelaySeconds: 1
  periodSeconds: 1
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 180

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 80

logging:
  # Set the logging format. Either: `text` or `json`
  format: text

volumes: []

volumeMounts: []

nodeSelector: {}

tolerations: []

affinity: {}

openaiApiUrl: "https://api.openai.com/v1"
openaiApiModel: "gpt-3.5-turbo"
openaiApiMaxTokens: 200
openaiApiTemperature: 0.0
openaiApiFormat: json_object
agentRegistryUrl: "http://lmos-operator:8080"
secretName: "lmos-runtime"
secretKey: "OPENAI_API_KEY"
cacheTtl: 1800
routerType: "EXPLICIT"
